---
title: "NEUORAL NETWORKS FOR APPROXIMATION"
output:
  word_document: default
  html_notebook: default
  html_document: default
---

# Download the data and libraries
```{r}
library(knitr)
library (psych)
library(dplyr)
library(ggplot2)

f <- read.csv2('flats.csv', header = TRUE, encoding = 'UNICOD')
describe(f)
```

# Visualising
```{r}
library(ggplot2)
par(mfrow = c(1, 3))
hist(f$rooms, col = 'dark blue', main = 'rooms', xlab = 'Value')
hist(f$m2, col = 'dark blue', main = 'm2', xlab = 'Value')
hist(f$price, col = 'dark blue', main = 'price', xlab = 'Value')
```

## Remove mistakes
```{r}
f <- f[f$price < 300000, ]
f <- f[f$price > 10000, ]
describe(f[,c('rooms','m2','price')])
```

## Factors as numeric
```{r}
f$location <- as.numeric(as.factor(f$location))-1
f$condition <- as.numeric(as.factor(f$condition))-1
f$type <- as.numeric(as.factor(f$type))-1
```

## Missing data
```{r}
f$rooms <- ifelse(is.na(f$rooms),round(mean(f$rooms,na.rm = TRUE)),f$rooms)
f$type <- ifelse(is.na(f$type),round(mean(f$type,na.rm = TRUE)),f$type)
```

# Visualising
```{r}
library(ggplot2)
par(mfrow = c(2, 3))
hist(f$rooms, col = 'dark blue', main = 'rooms', xlab = 'Value')
hist(f$m2, col = 'dark blue', main = 'm2', xlab = 'Value')
hist(f$price, col = 'dark blue', main = 'price', xlab = 'Value')
hist(log(f$rooms), col = 'dark blue', main = 'rooms', xlab = 'Value')
hist(log(f$m2), col = 'dark blue', main = 'm2', xlab = 'Value')
hist(log(f$price), col = 'dark blue', main = 'price', xlab = 'Value')
```

## Log
```{r}
f$rooms <- log(f$rooms)
f$m2 <- log(f$m2)
f$price <- log(f$price)
describe(f[,c('rooms','m2','price')])
```

## Replace ejections with max (no need)
```{r}
f$rooms <- ifelse(f$rooms < mean(f$rooms)+sd(f$rooms)*3,f$rooms,mean(f$rooms)+sd(f$rooms)*3)
f$rooms <- ifelse(f$rooms > mean(f$rooms)-sd(f$rooms)*3,f$rooms,mean(f$rooms)-sd(f$rooms)*3)

f$price <- ifelse(f$price < mean(f$price)+sd(f$price)*3,f$price,mean(f$price)+sd(f$price)*3)
f$price <- ifelse(f$price > mean(f$price)-sd(f$price)*3,f$price,mean(f$price)-sd(f$price)*3)

f$m2 <- ifelse(f$m2 < mean(f$m2)+sd(f$m2)*3,f$m2,mean(f$m2)+sd(f$m2)*3)
f$m2 <- ifelse(f$m2 > mean(f$m2)-sd(f$m2)*3,f$m2,mean(f$m2)-sd(f$m2)*3)

describe(f[,c('rooms','m2','price')])
```

## Splitting the scaled dataset into the TRAIN set and TEST set
```{r}
set.seed(123)
library(caTools)
split = sample.split(f$price, SplitRatio = 0.8)
f_train = subset(f, split == TRUE)
f_test = subset(f, split == FALSE)
```

## Features Scaling
```{r}
mr <- mean(f_train$rooms)
sr <- sd(f_train$rooms)
mm <- mean(f_train$m2)
sm <- sd(f_train$m2)
mp <- mean(f_train$price)
sp <- sd(f_train$price)

f_train_sc <- f_train
f_test_sc <- f_test
f_train_sc$rooms <- (f_train$rooms-mr)/sr
f_test_sc$rooms <- (f_test$rooms-mr)/sr
f_train_sc$m2 <- (f_train$m2-mm)/sm
f_test_sc$m2 <- (f_test$m2-mm)/sm
f_train_sc$price <- (f_train$price-mp)/sp
f_test_sc$price <- (f_test$price-mp)/sp

head (f_train_sc)
```
# Fitting Linear Regression to the Training set
```{r}
lr <- lm(price ~ ., f_train_sc)
summary(lr)
```

# Fitting the NN
```{r results='hide'}
library(nnet)
ff_ap <- nnet(price ~ rooms + location + condition + m2, f_train_sc, linout = TRUE ,size = 4, maxit = 10000)
library(graphics)
source(file = 'plot.nnet.R')
plot.nnet(ff_ap)
```

## Prediction
```{r}
p_y_train <- predict(ff_ap, f_train_sc)
p_y_test <- predict(ff_ap, f_test_sc)
```

## Invert the effect of the scaling
```{r}
y_train <- p_y_train*sp+mp
y_test <- p_y_test*sp+mp
```

## MSE
```{r}
train_mse <- sum((f_train$price-y_train)^2)/length(f_train$price)
test_mse <- sum((f_test$price-y_test)^2)/length(f_test$price)

train_mse
test_mse
```

## Visualising
```{r}
library(ggplot2)
ggplot() +
  geom_point(aes(f_train$m2, f_train$price),colour = 'red') +
  geom_point(aes(f_test$m2, f_test$price),colour = 'dark green') +
  geom_point(aes(f_test$m2, y_test),colour = 'blue', size = 3, alpha=0.5) +
  ggtitle('Price vs m2') +
  xlab('m2') +
  ylab('price')
```



# Fit NN-2 
```{r  results='hide'}
library(neuralnet)

# fit neural network
nn = neuralnet(price ~ condition + m2, f_train_sc, hidden = 3, linear.output = T)

# plot neural network
plot(nn)
```

```{r}
p_y_train_nn <- predict(nn, f_train_sc)
p_y_test_nn <- predict(nn, f_test_sc)
```

## Invert the effect of the scale function
```{r}
y_train_nn <- p_y_train_nn*sp+mp
y_test_nn <- p_y_test_nn*sp+mp
```

## MSE
```{r}
train_mse_nn <- sum((f_train$price-y_train_nn)^2)/length(f_train$price)
test_mse_nn <- sum((f_test$price-y_test_nn)^2)/length(f_test$price)

train_mse_nn
test_mse_nn
```

## Visualising
```{r}
library(ggplot2)
ggplot() +
  geom_point(aes(f_train$m2, f_train$price),colour = 'red') +
  geom_point(aes(f_test$m2, f_test$price),colour = 'dark green') +
  geom_point(aes(f_test$m2, y_test),colour = 'blue', size = 3, alpha=0.5) +
  ggtitle('Price vs m2') +
  xlab('m2') +
  ylab('price')
```

## Compare models
```{r}
ggplot() +
  geom_point(aes(f_test$price, y_test),colour = 'red') +
  geom_point(aes(f_test$price, y_test_nn),colour = 'dark green', size = 3, alpha=0.5) +
  geom_abline(intercept=0, slope=1)
```